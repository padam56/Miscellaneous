{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.6.9"
    },
    "colab": {
      "name": "Build a Convolutional Neural Network.ipynb",
      "provenance": []
    },
    "widgets": {
      "application/vnd.jupyter.widget-state+json": {
        "9fdb355a44e64bf798319012cb3e32dd": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "state": {
            "_view_name": "HBoxView",
            "_dom_classes": [],
            "_model_name": "HBoxModel",
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "box_style": "",
            "layout": "IPY_MODEL_b0039c0bf504482b9dd8db89008f9545",
            "_model_module": "@jupyter-widgets/controls",
            "children": [
              "IPY_MODEL_34fbe8264cba46638bdb5636f4f14999",
              "IPY_MODEL_54d568fff2dd4815b84bf5a8a1ce4750"
            ]
          }
        },
        "b0039c0bf504482b9dd8db89008f9545": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "34fbe8264cba46638bdb5636f4f14999": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "state": {
            "_view_name": "ProgressView",
            "style": "IPY_MODEL_b9633a85cfde49bf9a1561dfe4d78171",
            "_dom_classes": [],
            "description": "",
            "_model_name": "FloatProgressModel",
            "bar_style": "success",
            "max": 170498071,
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "value": 170498071,
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "orientation": "horizontal",
            "min": 0,
            "description_tooltip": null,
            "_model_module": "@jupyter-widgets/controls",
            "layout": "IPY_MODEL_884ce08b5297410198da45af1691401e"
          }
        },
        "54d568fff2dd4815b84bf5a8a1ce4750": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "state": {
            "_view_name": "HTMLView",
            "style": "IPY_MODEL_1e3c9efbd9a94f8b8d8222edebd8e6e5",
            "_dom_classes": [],
            "description": "",
            "_model_name": "HTMLModel",
            "placeholder": "â€‹",
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "value": " 170499072/? [00:06&lt;00:00, 24708571.50it/s]",
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "description_tooltip": null,
            "_model_module": "@jupyter-widgets/controls",
            "layout": "IPY_MODEL_6fa407859ac040f1bc1cce20b969ce5d"
          }
        },
        "b9633a85cfde49bf9a1561dfe4d78171": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "state": {
            "_view_name": "StyleView",
            "_model_name": "ProgressStyleModel",
            "description_width": "initial",
            "_view_module": "@jupyter-widgets/base",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.2.0",
            "bar_color": null,
            "_model_module": "@jupyter-widgets/controls"
          }
        },
        "884ce08b5297410198da45af1691401e": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "1e3c9efbd9a94f8b8d8222edebd8e6e5": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_view_name": "StyleView",
            "_model_name": "DescriptionStyleModel",
            "description_width": "",
            "_view_module": "@jupyter-widgets/base",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.2.0",
            "_model_module": "@jupyter-widgets/controls"
          }
        },
        "6fa407859ac040f1bc1cce20b969ce5d": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        }
      }
    },
    "accelerator": "TPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "DNP-cPzz0yhT"
      },
      "source": [
        "### Welcome to Deep Learning with PyTorch Series of project \n",
        "\n",
        "- Deep Learning with PyTorch : Build a Neural Network \n",
        "- **Deep Learning with PyTorch : Convolutional Neural Network**\n",
        "- Deep Learning with PyTorch : Neural Style Transfer\n",
        "- Many more coming"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "SAqxLiaS0yhU"
      },
      "source": [
        "# Deep Learning with PyTorch : Build a Convolutional Neural Network"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "AnMR9ryS0yhW"
      },
      "source": [
        "import numpy as np \n",
        "import matplotlib.pyplot as plt\n",
        "import torch "
      ],
      "execution_count": 1,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "PtNYXUUf0yhX"
      },
      "source": [
        "## Task 1 : Load CIFAR-10 Dataset"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "VJ4e9nJu0yhX"
      },
      "source": [
        "![](cifar-10.png)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "6etFveFM0yhY"
      },
      "source": [
        "PyTorch transforms : https://pytorch.org/docs/stable/torchvision/transforms.html\n",
        "- **For CIFAR-10 Dataset Channel mean is 0.4914, 0.4822, 0.4465**\n",
        "- **Channel wise Standard Deviation is 0.2470, 0.2435, 0.2616**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "FkJpbtt-0yha"
      },
      "source": [
        "from torchvision import transforms as T, datasets"
      ],
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "4ePtXllW0yha"
      },
      "source": [
        "* ToTensor() : converts numpy or PIL images to tensor. It also converts your image dimension to C x H x W because in pytorch for network input channel should be first \n",
        "\n",
        "* Normalize() : Takes channel wise mean-list and channel wise standard deviation-list"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-VDI9YrU0yhb"
      },
      "source": [
        "data_transforms = T.Compose([\n",
        "    T.ToTensor(), #H x W x C -> C x H x W\n",
        "    T.Normalize(mean = [0.4914, 0.4822, 0.4465], std = [0.2470, 0.2435, 0.2616])\n",
        "])"
      ],
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "u9gtWsyD0yhc"
      },
      "source": [
        "#### Parameters in datasets submodule\n",
        "\n",
        "* data_path\n",
        "* train : True (to load train set) or False (to load test set)\n",
        "* download : True (to download) or False\n",
        "* transform : to apply transformation on data\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "6Y36n73W0yhd"
      },
      "source": [
        "CIFAR-10 consists of 60,000 tiny 32 x 32 x 3(RGB) images, labeled with an interger corresponding to 1 of 10 : classes = ('plane', 'car', 'bird', 'cat','deer', 'dog', 'frog', 'horse', 'ship', 'truck')"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 140,
          "referenced_widgets": [
            "9fdb355a44e64bf798319012cb3e32dd",
            "b0039c0bf504482b9dd8db89008f9545",
            "34fbe8264cba46638bdb5636f4f14999",
            "54d568fff2dd4815b84bf5a8a1ce4750",
            "b9633a85cfde49bf9a1561dfe4d78171",
            "884ce08b5297410198da45af1691401e",
            "1e3c9efbd9a94f8b8d8222edebd8e6e5",
            "6fa407859ac040f1bc1cce20b969ce5d"
          ]
        },
        "id": "zNkhjYCW0yhd",
        "outputId": "35f2d7fc-1b51-4e91-f622-2901286ad198"
      },
      "source": [
        "train_ds = datasets.CIFAR10('cifar10/', train = True, download = True, transform = data_transforms)\n",
        "test_ds = datasets.CIFAR10('cifar10/', train = False, download = True, transform = data_transforms)"
      ],
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Downloading https://www.cs.toronto.edu/~kriz/cifar-10-python.tar.gz to cifar10/cifar-10-python.tar.gz\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "display_data",
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "9fdb355a44e64bf798319012cb3e32dd",
              "version_minor": 0,
              "version_major": 2
            },
            "text/plain": [
              "HBox(children=(FloatProgress(value=0.0, max=170498071.0), HTML(value='')))"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "stream",
          "text": [
            "\n",
            "Extracting cifar10/cifar-10-python.tar.gz to cifar10/\n",
            "Files already downloaded and verified\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "pQ1Uo2Du0yhe",
        "outputId": "9634d2a5-57d2-4878-e078-4c7811d96898"
      },
      "source": [
        "print(\"Size of train set {}\".format(len(train_ds)))\n",
        "print(\"Size of test set {}\".format(len(test_ds)))"
      ],
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Size of train set 50000\n",
            "Size of test set 10000\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "xX8y70dI0yhe"
      },
      "source": [
        "## Task 2 : Plot examples from dataset"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "5wYA9rI20yhf"
      },
      "source": [
        "classes = ['plane', 'car', 'bird', 'cat', 'deer', 'dog', 'frog', 'horse', 'ship', 'track']"
      ],
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 319
        },
        "id": "ZDNBFLkh0yhf",
        "outputId": "c5d7bb31-72f2-4fc7-d024-3a4ff126afbe"
      },
      "source": [
        "index = 99\n",
        "image, label = train_ds[index]\n",
        "#print(image.shape)\n",
        "image = image.permute(1,2,0) #C(0) x H(1) x W(2)\n",
        "#image = image * torch.Tensor([0.2470, 0.2435, 0.2616]) + torch.Tensor([0.4914, 0.4822, 0.4465]) #denormalizing to see the original image, multiplying & passing the channel wise SD and Mean values!\n",
        "#print(image.shape)\n",
        "plt.imshow(image)\n",
        "plt.title(classes[label]);"
      ],
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Clipping input data to the valid range for imshow with RGB data ([0..1] for floats or [0..255] for integers).\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": [],
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "20Ffkfg-0yhf"
      },
      "source": [
        "## Task 3 : Load dataset into batches"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ZQgvqo9F0yhg"
      },
      "source": [
        "from torch.utils.data import DataLoader, random_split"
      ],
      "execution_count": 8,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "lh_-5Ro90yhg"
      },
      "source": [
        "train_dataset, valid_dataset = random_split(train_ds, (45000, 5000))"
      ],
      "execution_count": 9,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "BM_N9OjM0yhg"
      },
      "source": [
        "trainloader = DataLoader(train_dataset, batch_size = 64, shuffle = True)\n",
        "validloader = DataLoader(valid_dataset, batch_size = 64, shuffle = True)\n",
        "testloader  = DataLoader(test_ds, batch_size = 64, shuffle = True)"
      ],
      "execution_count": 10,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "j4bItXqI0yhh",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "5244592f-ece7-4d93-e55e-b05748720822"
      },
      "source": [
        "print(\"Total Batches created in Train Loader : {}\".format(len(trainloader)))\n",
        "print(\"Total Batches created in Train Loader : {}\".format(len(validloader)))\n",
        "print(\"Total Batches created in Train Loader : {}\".format(len(testloader)))\n",
        "print(\"Size of train dataset {}\".format(len(trainloader.dataset)))\n",
        "print(\"Size of train dataset {}\".format(len(validloader.dataset)))\n",
        "print(\"Size of train dataset {}\".format(len(testloader.dataset)))"
      ],
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Total Batches created in Train Loader : 704\n",
            "Total Batches created in Train Loader : 79\n",
            "Total Batches created in Train Loader : 157\n",
            "Size of train dataset 45000\n",
            "Size of train dataset 5000\n",
            "Size of train dataset 10000\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "5SOul_b90yhh",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "334a8104-8068-4219-8537-3e2d6482f9f8"
      },
      "source": [
        "dataiter = iter(trainloader)\n",
        "\n",
        "images,labels = dataiter.next()\n",
        "\n",
        "print(images.shape)\n",
        "print(labels.shape)"
      ],
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "torch.Size([64, 3, 32, 32])\n",
            "torch.Size([64])\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "mWUWZnjZ0yhh"
      },
      "source": [
        "## Task 4 : Create Convolutional Neural Network "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "LeTYnhey0yhi"
      },
      "source": [
        "from torch import nn\n",
        "import torch.nn.functional as F"
      ],
      "execution_count": 13,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "XXoRR1MZ0yhi"
      },
      "source": [
        "\n",
        "k : kernel_size or filters \n",
        "<br>\n",
        "p : padding \n",
        "<br>\n",
        "s : stride \n",
        "<br>\n",
        "W : Width \n",
        "<br>\n",
        "H : Height \n",
        "\n",
        "\\begin{equation*}\n",
        "For Same padding = \\frac{k - 1}{2} \\\\\n",
        "\\end{equation*}\n",
        "\n",
        "\\begin{equation*}\n",
        "W[next] = \\frac{W[previous] + 2p - k}{s} + 1 \\\\\n",
        "\\end{equation*}\n",
        "\n",
        "\\begin{equation*}\n",
        "H[next] = \\frac{H[previous] + 2p - k}{s} + 1 \\\\\n",
        "\\end{equation*}"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "qwiwnpEI0yhj",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 196
        },
        "outputId": "8647115b-97e2-4ca1-fdb5-1d74b8e63942"
      },
      "source": [
        "'''\n",
        "3 x 32 x 32 (input)\n",
        "\n",
        "       | k = (3,3), p = 1, s = 1 , out_channels = 16,operation = convolutional  #conv1\n",
        "       V activation = relu \n",
        "       \n",
        "16 x 32 x 32\n",
        "\n",
        "       | k = (2,2), s = 2, operation = Max Pooling #maxpool\n",
        "       V \n",
        "       \n",
        "16 x 15 x 15\n",
        "\n",
        "       | k = (3,3), p = 1, s = 1, out_channels = 32, operation = convolutional #conv2\n",
        "       V activation = relu\n",
        "       \n",
        "32 x 15 x 15 \n",
        "\n",
        "       | k = (2,2), s = 2, operation = Max Pooling #maxpool\n",
        "       V \n",
        "       \n",
        "32 x 8 x 8\n",
        "\n",
        "       | k = (3,3), p = 1 , s = 1 , out_channels = 64, operation = convolutional #conv3\n",
        "       V activation = relu \n",
        "       \n",
        "64 x 8 x 8\n",
        "\n",
        "       | k = (2,2), s = 2 , operation = MaxPooling #maxpool\n",
        "       V\n",
        "\n",
        "64 x 4 x  4\n",
        "    \n",
        "       |  operation = Flatten\n",
        "       V\n",
        "500\n",
        "\n",
        "       |  linear,activation = relu #linear1\n",
        "       V\n",
        "\n",
        "128\n",
        "       |  linear,activation = relu #linear2\n",
        "       V\n",
        "\n",
        "10  linear, activation = log_softmax #linear3\n",
        "'''"
      ],
      "execution_count": 14,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            },
            "text/plain": [
              "'\\n3 x 32 x 32 (input)\\n\\n       | k = (3,3), p = 1, s = 1 , out_channels = 16,operation = convolutional  #conv1\\n       V activation = relu \\n       \\n16 x 32 x 32\\n\\n       | k = (2,2), s = 2, operation = Max Pooling #maxpool\\n       V \\n       \\n16 x 15 x 15\\n\\n       | k = (3,3), p = 1, s = 1, out_channels = 32, operation = convolutional #conv2\\n       V activation = relu\\n       \\n32 x 15 x 15 \\n\\n       | k = (2,2), s = 2, operation = Max Pooling #maxpool\\n       V \\n       \\n32 x 8 x 8\\n\\n       | k = (3,3), p = 1 , s = 1 , out_channels = 64, operation = convolutional #conv3\\n       V activation = relu \\n       \\n64 x 8 x 8\\n\\n       | k = (2,2), s = 2 , operation = MaxPooling #maxpool\\n       V\\n\\n64 x 4 x  4\\n    \\n       |  operation = Flatten\\n       V\\n500\\n\\n       |  linear,activation = relu #linear1\\n       V\\n\\n128\\n       |  linear,activation = relu #linear2\\n       V\\n\\n10  linear, activation = log_softmax #linear3\\n'"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 14
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "hjdR08bO0yhk"
      },
      "source": [
        "class MyModel(nn.Module):\n",
        "\n",
        "  def __init__(self):\n",
        "    super(MyModel,self).__init__()\n",
        "\n",
        "    self.conv_1 = nn.Conv2d(in_channels=3, out_channels=16, kernel_size=(3,3), padding=1, stride=1)\n",
        "    self.conv_2 = nn.Conv2d(in_channels=16, out_channels=32, kernel_size=(3,3), padding=1, stride=1)\n",
        "    self.conv_3 = nn.Conv2d(in_channels=32, out_channels=64, kernel_size=(3,3), padding=1, stride=1)\n",
        "    self.maxpool = nn.MaxPool2d(kernel_size=(2,2), stride=2)\n",
        "\n",
        "    self.linear_1 = nn.Linear(in_features=1024, out_features=500)\n",
        "    self.linear_2 = nn.Linear(in_features=500, out_features=128)\n",
        "    self.linear_3 = nn.Linear(in_features=128, out_features=10)\n",
        "\n",
        "  def forward(self, images):\n",
        "    #images : 3 x 32 x 32\n",
        "    a1 = self.maxpool(F.relu(self.conv_1(images)))\n",
        "    a2 = self.maxpool(F.relu(self.conv_2(a1)))\n",
        "    a3 = self.maxpool(F.relu(self.conv_3(a2)))\n",
        "    a3 = a3.view(a3.shape[0],-1) #(bs,64*4*4) -> (bs,64*4*4 -> (bs,1024)) #flatten\n",
        "    a4 = F.relu(self.linear_1(a3))\n",
        "    a5 = F.relu(self.linear_2(a4))\n",
        "    a6 = F.log_softmax(self.linear_3(a5), dim=1)\n",
        "\n",
        "    return a6"
      ],
      "execution_count": 15,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "P8EAVO-G0yhk",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "7d3e6223-b942-4b64-d983-2ed563f44564"
      },
      "source": [
        "model = MyModel()\n",
        "model"
      ],
      "execution_count": 16,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "MyModel(\n",
              "  (conv_1): Conv2d(3, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
              "  (conv_2): Conv2d(16, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
              "  (conv_3): Conv2d(32, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
              "  (maxpool): MaxPool2d(kernel_size=(2, 2), stride=2, padding=0, dilation=1, ceil_mode=False)\n",
              "  (linear_1): Linear(in_features=1024, out_features=500, bias=True)\n",
              "  (linear_2): Linear(in_features=500, out_features=128, bias=True)\n",
              "  (linear_3): Linear(in_features=128, out_features=10, bias=True)\n",
              ")"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 16
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ftVTWMiF0yhk"
      },
      "source": [
        "from torchsummary import summary"
      ],
      "execution_count": 17,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "0aNbQd3h0yhl",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "b17f86ef-d5c9-4665-e66b-92919cb39dae"
      },
      "source": [
        "summary(model, input_size= (3,32,32))"
      ],
      "execution_count": 18,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "----------------------------------------------------------------\n",
            "        Layer (type)               Output Shape         Param #\n",
            "================================================================\n",
            "            Conv2d-1           [-1, 16, 32, 32]             448\n",
            "         MaxPool2d-2           [-1, 16, 16, 16]               0\n",
            "            Conv2d-3           [-1, 32, 16, 16]           4,640\n",
            "         MaxPool2d-4             [-1, 32, 8, 8]               0\n",
            "            Conv2d-5             [-1, 64, 8, 8]          18,496\n",
            "         MaxPool2d-6             [-1, 64, 4, 4]               0\n",
            "            Linear-7                  [-1, 500]         512,500\n",
            "            Linear-8                  [-1, 128]          64,128\n",
            "            Linear-9                   [-1, 10]           1,290\n",
            "================================================================\n",
            "Total params: 601,502\n",
            "Trainable params: 601,502\n",
            "Non-trainable params: 0\n",
            "----------------------------------------------------------------\n",
            "Input size (MB): 0.01\n",
            "Forward/backward pass size (MB): 0.28\n",
            "Params size (MB): 2.29\n",
            "Estimated Total Size (MB): 2.58\n",
            "----------------------------------------------------------------\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "vrV3YD0a0yhl"
      },
      "source": [
        "## Task 5 : Training loop"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "GVthq0UV0yhl"
      },
      "source": [
        "from torch import optim\n",
        "from utils import multiclass_accuracy\n",
        "from tqdm import tqdm\n",
        "\n",
        "criterion = nn.NLLLoss() #(logps,true_labels)\n",
        "optimizer = optim.Adam(model.parameters(), lr=0.003)\n",
        "epochs = 10"
      ],
      "execution_count": 21,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "YRrr5Ywl0yhl"
      },
      "source": [
        "for i in range(epochs):\n",
        "  train_loss = 0.0\n",
        "  train_acc = 0.0\n",
        "  valid_loss = 0.0\n",
        "  valid_acc = 0.0\n",
        "\n",
        "  model.train()\n",
        "  \n",
        "  for images, labels in tqdm(trainloader):\n",
        "    \n",
        "    logps = model(images) #output ps\n",
        "    \n",
        "    loss = criterion(logps,labels)\n",
        "    \n",
        "    optimizer.zero_grad()\n",
        "    loss.backward() #dw,db\n",
        "    optimizer.step() #w = w-lr*dw, b = b-lr*db #updating the values of weights and biases\n",
        "\n",
        "    train_loss += loss.item()\n",
        "    ps = torch.exp(logps) #log_softmax -> softmax #removing log from log prob to get the softmax probabilities\n",
        "    train_acc += multiclass_accuracy(ps,labels)\n",
        "  \n",
        "  model.eval() #make sures to switch off the dropout, batch norm\n",
        "\n",
        "  for images, labels in tqdm(validloader):\n",
        "\n",
        "    logps = model(images)\n",
        "    loss = criterion(logps, labels)\n",
        "\n",
        "    valid_loss += loss.item() #adding all the batch loss\n",
        "    ps = torch.exp(logps)\n",
        "    valid_acc += multiclass_accuracy(ps, labels) #ps = probabilities\n",
        "\n",
        "    #avging all trainloss, validloss and accuracies\n",
        "    avg_train_loss = train_loss/len(trainloader)\n",
        "    avg_valid_loss = valid_loss/len(trainloader)\n",
        "    avg_train_acc = train_acc/len(trainloader)\n",
        "    avg_valid_acc = valid_acc/len(trainloader)\n",
        "\n",
        "    print(\"Epoch: {} Train Loss : {:.4f} Train Acc : {:.4f}\".format(i,avg_train_loss, avg_train_acc))\n",
        "    print(\"Epoch: {} Valid Loss : {:.4f} Valid Acc : {:.4f}\".format(i,avg_valid_loss, avg_valid_acc))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "C8rxkF0o0yhm"
      },
      "source": [
        "## Task 6 : Evaluate model "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "SDL0fCbr0yhm"
      },
      "source": [
        "from utils import view_classify"
      ],
      "execution_count": 23,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "FzD1EFk30yhm",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "76c0c77a-4eb6-4311-ad24-3d5b19c8616f"
      },
      "source": [
        "test_loss = 0.0\n",
        "test_acc= 0.0\n",
        "\n",
        "model.eval() #dropout, batchnorm\n",
        "\n",
        "for images, labels in tqdm(testloader):\n",
        "\n",
        "    logps = model(images)\n",
        "    loss = criterion(logps, labels)\n",
        "    test_loss += loss.item() #adding all the batch loss\n",
        "    ps = torch.exp(logps)\n",
        "    test_acc += multiclass_accuracy(ps, labels)\n",
        "\n",
        "avg_test_loss = test_loss/len(testloader)\n",
        "avg_test_acc  = test_acc/len(testloader)\n",
        "print(\"Test Loss : {:.4f} Test Acc : {:.4f}\".format(avg_test_loss, avg_test_acc))"
      ],
      "execution_count": 24,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 157/157 [00:06<00:00, 25.86it/s]"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Test Loss : 1.0923 Test Acc : 0.6949\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-fDCHzYr0yhn",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 243
        },
        "outputId": "cf2d79b6-9bba-48ef-97d5-7397a5550f9b"
      },
      "source": [
        "dataiter = iter(testloader)\n",
        "images, labels = dataiter.next()\n",
        "\n",
        "index = 30\n",
        "logps = model(images[index].unsqueeze(0))\n",
        "ps = torch.exp(logps)\n",
        "\n",
        "view_classify(images[index],ps)"
      ],
      "execution_count": 33,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "image/png": "iVBORw0KGgoAAAANSUhEUgAAAagAAADiCAYAAAAbBlN+AAAABHNCSVQICAgIfAhkiAAAAAlwSFlzAAALEgAACxIB0t1+/AAAADh0RVh0U29mdHdhcmUAbWF0cGxvdGxpYiB2ZXJzaW9uMy4yLjIsIGh0dHA6Ly9tYXRwbG90bGliLm9yZy+WH4yJAAAgAElEQVR4nO3deZhcZZU/8O+3UlQ6nU6l02lCEpLQCUlIQsISwo7KJiqj4OigsqggiqCiM4ozzOg4jNvo4DIqCKKj7IIwKlFEQHYDAZIAWQiEEDohhGx0Op2iKYpKnd8fdeOv6PfcppNUd91Ovp/n6Yfqc9+69dYS3r73njqHZgYREZGkSdV6AiIiIh4tUCIikkhaoEREJJG0QImISCJpgRIRkUTSAiUiIomkBUpE+hzJS0heX+t5bC+SLSSNZHoH728kJ8ZsO5PkXd5YkleS/Pcdm3X/pQVKRHoFyTNIziOZI/kyyTtIHlOjuRjJV6O5vETyByQH1GIucczsBjM7KWbb+Wb2DQAgeSzJ1X07u9rQAiUiVUfyiwD+B8C3AewFYByAnwI4tYbTOtDMGgCcAOAMAJ/qOmBHj4ykd2iBEpGqIjkUwNcBfNbMfmtmr5rZG2b2BzP7csx9biG5luRmkg+S3L9i28kknya5JTr6uSiKN5P8I8l2km0kHyL5lv9PM7NnADwEYHrFKbtzSa4CcC/JFMmvklxJcj3Ja6PnVOkTJNdER4YXVcz1MJKPRHN6meRlJDNd7nsyyRUkN5K8dNucSZ5N8q8xr8/VJL9JcjCAOwCMjo4GcyRHk+wkObxi/EySG0ju8VavR5JpgRKRajsSQB2A323Hfe4AMAnACAALANxQse1/AXzazIYAmA7g3ij+JQCrAeyJ8lHavwF4y9ptJKcBeBuAJyrC7wAwFcC7AJwd/RwHYAKABgCXddnNcdF8TwLwLyRPjOJbAfwTgGaUX4cTAHymy33/HsAsADNRPqL8xFvNeRszexXAewCsMbOG6GcNgPsBfKhi6EcB3GRmb/R030mkBUpEqm04gI1mVuzpHczsl2a2xcxeB3AJgAMrjlreADCNZNbMNpnZgor4KAD7REdoD1n3xUUXkNwE4A8AfgHgVxXbLomO9F4DcCaAH5jZCjPLAfhXAB/pcvrvP6Pxi6L9nB49j/lmNtfMimbWCuBnKC9+lb5rZm1mtgrl06Cn9/R16sY1AM4CgOja2ukArqvCfmtKC5SIVNsrAJp7ej2H5ACS3yH5PMkOAK3Rpubovx8EcDKAlSQfIHlkFL8UwHIAd0WnzC5+i4eaaWbDzGxfM/uqmZUqtr1YcXs0gJUVv68EkEb5KM0bvzK6D0hOjk47ro2ey7crnke3991Jt6G8iI8H8E4Am83ssSrst6a0QIlItT0C4HUA7+/h+DNQPtV1IoChAFqiOAHAzB43s1NRPv33ewC/ieJbzOxLZjYBwCkAvkjyhB2cc+WR1xoA+1T8Pg5AEcC6itjYLtvXRLevAPAMgElmlkX5tCO7PFbcfXdkruWAWR7l1+UslE/v9fujJ0ALlIhUmZltBvA1AJeTfD/JepJ7kHwPyf927jIE5QXtFQD1KB91AABIZqLvBw2Nrqd0AChF295LciJJAtiM8vWfUrD37fdrAP9EcjzJhmg+N3c5Zfnv0fPaH8A5AG6ueC4dAHIkpwC4wNn/l0kOIzkWwBcq7ttT6wAMdxI3rkX52tkp0AIlIuIzs+8D+CKArwLYgPJprc+hfATU1bUon+p6CcDTAOZ22f5RAK3RKbPzUb5GBJSTFP4CIIfyUdtPzey+Kkz/lyj/D/5BAC8AyAO4sMuYB1A+vXgPgO+Z2bYv2F6E8hHhFgA/h7/43AZgPoAnAdyOchJIj0VZiL8GsCLKFhwdxeegvEAvMLOV3e2jv6AaFoqI7BpI3gvgRjP7Ra3nUg1aoEREdgEkDwVwN4CxZral1vOpBp3iExHp50heg/Lpzn/cVRYnQEdQIiKSUN1+T+HMsz7mrl4lJ08mk/F31ZCtc+P19X4FjlSq56WwCgU/YSedGhTEikX/O4Nx887Uda1OUlbC1iBWP8h/jqVSOBYAcq92BrGOXIc/tsOPl0r+HxbptFP/Mu0fKBeL/utXXx++ftGjBpGO9tdi9tHgxuvqBoZ7jXsuGb+WZyrm+XTmwi/NZxu6JjqV/fA73+ia+isiCaNTfCIikkiq3CvSTzQ3N1tLS0utpyFSdfPnz99oZnt2jWuBEuknWlpaMG/evFpPQ6TqSLrf29IpPhERSSQtUCIikkjdnuKri8m0KxbC7LRUzFKXy4UZawDQ0eFn1Y0cGZyGRCpm5/VORlh5fJj9FZPEFysmUQzFUviaeFmNAJDJ+K9fA8J5Nwzys96Kjf5zzHf62XO5XD6ItXfm3LGluCcZ83dLpi58PvUNfrZjIe+3ofE+D8Win+2Ydh4PADYXXvf33RHGhzX6r5OIJJ+OoEREJJG0QImISCJpgRIRkUTSAiUiIonUbZLEiBFZN+6VyGka5o9dv2GTG58/b4kbnzZ1YhCLK4XT1OSXsfHW3ULBv2i/fsMGN57LFdz4A/cvDmIzZoZzBoARI+r9+F7ha9WYbXLH5jv9eXS0+yWQiqVXgphfiAloaPQTM9o2trtxr7RUCn4iQ1xyjPc+bI1JkoC/C+SKr7rxlPNxLhb8BBERST4dQYmISCJpgRLpIZKNJD9TpX0dS/KP1diXyK5KC5RIzzUCCBYokioZJtILtECJ9Nx3AOxL8kmSj5N8iORsAE+TbCH5twuUJC8ieUl0eyLJv5B8iuQCkvtW7pTkoSSf6BoX2d3pLz+RnrsYwHQzO4jksQBuj35/gWRLN/e7AcB3zOx3JOtQ/sNwLACQPArATwCcamarenPyIv1N96WOBvoZWoVUmInV0ODniq160c+e27hxsxtv2xTGW/bZ2x0bl8W3du16Zx5r3bGdnWFpIABobm725+dkzz37zAp37IR9D4t5zDA9rVD0m/OVYt6ip18InyMALF28PIjtNXK4O3Z02s8ybG/3Mwe3dIQZcW6DRABxB+clpy5UOu0/xwExx/dDnM9fmVOCK+9nkVbJY2b2QncDSA4BsLeZ/Q4AzCwfxQFgKoCrAJxkZmti7n8egPMAYNy4cdWbuUg/oFN8IjuuMt+9iDf/e4rL7q/0MoA8gIPjBpjZVWY2y8xm7blnWKdSZFemBUqk57YAGBKzbR2AESSHkxwI4L0AYGZbAKwm+X4AIDmQ5LZD13YAfwfgv6JThiJSQQuUSA+Z2SsA5kTJEJd22fYGgK8DeAzA3QCeqdj8UQCfJ7kQwMMARlbcbx3Ki9nlJA/v3Wcg0r8oSUJkO5jZGd1s+zGAHzvx5wAc3yW8AsD90fZVAPav3ixFdg06ghIRkUTq9gjKy6gDgDFjRwSxpka/llyx+KIbT6X8DMF2J1Ms2zTYHduQ9aef7Qjjo/dsdMcumL/UjRfyfofDTF1YF3D8xFHu2FTKn1+hGO4j7ycTorPgZ9R1FunHS2FW3YY2v97gGyW/5t7gBv/1HpIO37PXYxonxtU+LDl1HFMpv+khYhpBDij6+96KcC6ltP9cRCT5dAQlIiKJpAVKREQSSQuUiIgkkhYoERFJJC1QIiKSSN131N0zpobbyLBOXS73ujt22tTJbvyRuU/5E3IyxUaM8DME29v8OmtPLnkmiDU1DnPHIqaW3JLFfn29VS+GGXFNTRvdsevW+i1hR40OsyBTKf/1y3X6HWFzHf6+R2TD1y+d9jsSD4CfDVfI+d1633Ay8woFP9sRpZi/fZxafPmYTMVUyn9vMnF/V2UGhvtIhzER6R90BCVSZSRbSQZ/xZE8heTFtZiTSH+kShIifcTMZgOYXet5iPQXOoIS2QkkB5O8PWpGuJjkh6NNF0bNCReRnBKNPZvkZdHtq0leSXIeyWUk31uzJyGSUFqgRHbOuwGsMbMDzWw6gD9H8Y1mNhPAFQAuirlvC4DDUK5ofmXUzPBNSJ4XLWLzNmzwK4KI7Kq6PcXX+dqrbtwrY7PmZT9RIJ/369WsXbfOjT/7TNhwb/myif788n6iwIrWsDnhsqLfsPDFVX7jv+XPv+zG3SU9JsEhbv1va3fmUvRrHWVi3qG6lJ+cUFcfPmax6JeVKhX8ckmv5f3nk3ISWAbGND3cWoxpWOiFncQJANijzk9wSGX8x2zIhvGGbIM7tooWAfg+ye8C+KOZPRQ1I/xttH0+gA/E3Pc3ZlYC8BzJFQCmAHiycoCZXYVyU0PMmjXLz3YR2UXpGpTITjCzZSRnAjgZwDdJ3hNt2rbKb0X8v7OuC44WIJEKOsUnshNIjgbQaWbXo9wjauZ23P00kimS+wKYAODZ3pijSH+lIyiRnTMDwKUkSwDeAHABgFt7eN9VKDc4zAI438xiatqL7J60QInsBDO7E8CdXcItFdvnATg2un01gKsrxv3FzM7v1QmK9GM6xSciIonUfcPCti1ufGFneKp8+TI/Sy5T72diZYf68fvuvjuIDarPumPTGX99LThJYU1NftmmOY/4DQtfz73kxk8+Lfy6yvRpE/z5DfCz5/Kvh6V9Cn5CIkoxlYSKMRvynU4GXky5n3TKj5disuq8P2cKcdl6VSgxlM74r19dTGZeJh1kaQMxzQ1rzczOrvUcRJJOR1AiIpJIWqBERCSRtECJ9BOLXtpc6ymI9CktUCIikkhaoEREJJG6zeJb6tTFA4BSKcyMSqf8zKqCMxYApsZkvqUQZm796bZ7nJHA1IOnuvG8U9euWPCz8uoGDXLjp3/hy278mCMPD2LpmMZ6cdlwxWJY0aYjpv5drvM1N97QMNiNp1Jhfb2ODr8h4PpNfjPEzpxfgzFfcOZY8j9CnSX/NdnSET5msbjVHZuOaSaZyvkpj8VcuO8M/H1vD5ItKNfZm77TOxORHtMRlEgvIqkvw4vsIC1QIj0zgOTPSS4heRfJQSQPIjmX5EKSvyM5DABI3k/yf0jOA/AFkqdFvaKeIvlgNGYAyUtJPh7d/9M1fXYiCaQFSqRnJgG43Mz2B9AO4IMArgXwL2Z2AMptN/6jYnzGzGaZ2fcBfA3Au8zsQACnRNvPBbDZzA4FcCiAT5Ec30fPRaRf0AIl0jMvmNm2Xk3zAewLoNHMHohi1wB4e8X4mytuzwFwNclPAdh2Ye0kAB8j+SSARwEMR3kRfJPKhoVbO5VmLruXbs+PH3LYIf6dnBJD2cFD3LFNTXv5O4+5iP65C8YGsW9960p37NSD9nPjJ73zqCD2ofee7Y795te/6MbHTfSTOOY+siiIlZykBwCYsl+LG882Dg1iG9v9i/lrN/kFrus2+ckna9aGjSNLToNJAEjFVDSKK6M0oWVMOI+Y933h835SSsr5k6itw096yGSc0kUAMjGJN3knAaMhruPj9qvMENkKoPEtxv8t08TMzid5OMqdc+eTPAQAAVwYFZuNVdmwcOCoSeoXJbsVHUGJ7JjNADaRfFv0+0cBPOANJLmvmT1qZl8DsAHAWJQroF9Aco9ozGSSfmqmyG5KGUYiO+7jAK4kWQ9gBYBzYsZdSnISykdN9wB4CsBClNtyLGC5R/wGAO/v9RmL9CNaoETegpm1Aphe8fv3KjYf4Yw/tsvvH/B2C+Dfoh8RcegUn4iIJJIWKBERSaRuT/FN2c+v7JJyUrHiytV4pYsAoDPvZ4q1tYWlfb773X91xx59eHB2JdbnP3ueG29uHObG/3L3Q2782l/d4ET90kBAmK0HAHvUh4/5RsHPakTGL8WEYkwnQ7ekU0zTvtRINzyowS9blXfKMU2eGmRGAwD2mbyvG7/lph8FsT/fN88d+/0fXufGGxoybrzO+VwOqYt5XfuhGXv7nyeRXZWOoEREJJG0QImISCJpgRLpJ9SwUHY3WqBERCSRtECJiEgidZvFt+y59W68M6ZhnMfL+AOA+no/E2vVi2EW2tNLn3PHrm3zT3m0tYeZgI8saHXH/vjyH7hxVKHRXbkaTuiN7Sn6GZOsF18KzntvYp5Lqd0Nv9bhx8tFvLs8WptfL2/zGv+j1bp0RRAbmfUzFdOlDjc+fqLfqLJhYJgx2v5KWJuwN5D8PIALACwwszP75EFFdnGqJCFSHZ8BcKKZrd4WIJk2s9g/MUSkezrFJ7KTSF4JYAKAO0huJnkdyTkAriPZQvLeqCnhPSTHRffZN2p2uIjkN0mGpdhFdnNaoER2kpmdD2ANgOMA/BDANJSPpk4H8BMA10RNDW8A8OPobj8C8CMzmwFgdbhXEdECJVJ9s81s24XQIwHcGN2+DsAxFfFbots3IoYaFsruTAuUSPXF1b7abmZ2VdQ6ftaAepU6kt1Lt0kSHe3+aXGv7l6h4F8LLhYL/gPHLI35Qjh+3LjR7tiPnuF3w01lskFs5iGH+Q9YlWy93uRnye0z0q8huH592HT1tVLcX95x2Xp+/boZkw4OYu/7wEnu2Dlzl7nxX/zst0EsH9PBN5fz5/388hfc+OD6gUFsXMzr1IceBvARlI+ezgSwrcjjXAAfRLk1/EdqMzWRZNMRlEjvuhDAOSQXotx19wtR/B8BfDGKT0TcdxJEdmNKMxepAjNriW5e0iW+EsDxzl1eAnCEmRnJjwDYr1cnKNIPaYESqY1DAFwWtXtvB/CJGs9HJHG0QInUgJk9BODA7bmP+kHJ7qbbBWrkKP8Cc9umTUEsFdOAMJ+nG0+l/Iduaqh3xvqXyg6YMdmNP/rQoiC2rLU6JW8Gp/cMYnHza8iGzwUASk6SScMQv9zPyJHNbnzvMX6zwZWtYamoYVn/fWys9xsTptJ+kkRTY5h8sn79K+7Ywc3D3XhD04gg9tRj892xG2OSdFIZ/3XN14UJNq/H7ENEkk9JEiIikkhaoEREJJG0QIn0E4te2oyWi29Hy8W313oqIn1CC5SIiCSSFiiRXkDyEpIX1XoeIv1Zt1l8pVTejacybwSxpqGD/Z1Y2EQOAHKdr/sTSoUZZJkhYQkbADj4qAPc+OLWDUFs3dLb/PnF+PZ//9SN5zavCWK/vv737tjT/uFEN16fDl+TUtF/PSaOH+/Gm0b4WXKNzU1B7IhDZ7ljYyoM4U+33+fGH350QRArFPzPyHtPPcqNP/1sWF5pY5tfcmn06DDjDwDq0v7noVQMn9D6nD8/EUk+HUGJVAnJr5BcRvKviCpDkDwo6vu0kOTvSA6L4odGsSdJXkpycU0nL5JAWqBEqoDkISgXfT0IwMkADo02XQvgX6J+UIsA/EcU/xWAT5vZQUh+xWKRmtACJVIdbwPwOzPrNLMOALMBDAbQaGYPRGOuAfB2ko0AhpjZI1Fc/aBEHFqgRBJM/aBkd6YFSqQ6HgTwfpKDSA4B8D6UGxduIvm2aMxHATxgZu0AtpA8PIqrH5SIo9ssvsZG/y+2whthtlQqZq1r6+h04x0dr7nxpuawblz7Zr9BaVu7n/n26gbvMeOanPq1AqdM39eNr1pRCmLZJr/W3ci9/Cy0WQeFnRUmjtnLHTtqn73dOFJ+JtumTR1BbM2GNnfs2JgMwYXPr3Tji5eF8X84833u2OxI/7n//H//HMTS6TArFADqYmoCLlu23H/MbFhbMJPx91FtZraA5M0AngKwHsDj0aaPA7iSZD2AFQDOieLnAvg5yRKAB6B+UCIBVTMXqRIz+xaAbzmbjnBiS6LECZC8GMC83pybSH+kBUqkNv6O5L+i/G9wJYCzazsdkeTRAiVSA2Z2M4Cbaz0PkSTTAiXST8zYeyjmfefvaj0NkT7TfcPCprA5HwCkS+HdSqUweQAAGv2eeGjP+kkSjUNj7uDNIx1TxqbeafIXW/HG3OiIEWFzPgBYvyZMTohLhWzb5F/3njYtTMAYvvd2NVfFH/7vejd+6233BrGmZj9hYcp+k9z4N/7LL/M0ZlS4n8Zmv3Hi/Y8868Y782ECy6SJ/j5KJf8zMmFMTAmk+rogNtwp/SQi/YPSzEVEJJF0ik+kn9jWD2p316rTnLsNHUGJiEgiaYESEZFE0gIlUgVqUChSfd1eg9q4PmzOBwDjxowOYoWCX66mUPSz+8aN88sDuWtmTIbgxCkT3fiSZeuD2D233B3zeL6Fi5e68fvveziIPfFE2MgPAPYZ4zcV7OwMs9PWzr/THXvTLWFpIAC4/Ge3uvET3vOOIPbJ097tjv3Fr37rxt/Ir3LjE6ccHsQeftzP1rv9z/5rcujMMHMwW+93m6hP+xmdUyaMdeO5jlwQG7GXn4maRCTTZhbTRlJk96MjKJEdFNOgcF+SfyY5n+RDJKdE8T1J/h/Jx6Ofo6P4JSSvIzkHwHW1ezYiyaMsPpEd0KVBYRrAAgDzAVwF4Hwzey6qVv5TAMcD+BGAH5rZX0mOA3AngKnR7qYBOMbM/C9+ieymtECJ7Ji/NSgEAJKzAdQBOArALeTfquRv+2b3iQCmVcSzJLedw5wdtziRPA/AeQAwINt/TleKVIMWKJHqSQFoj9q4e9uOMLM31TSJFqy4XjAws6tQPirDwFGT/LInIrsoXYMS2TFeg8JOAC+QPA0AWLathtVdAC7cdmeS3iImIhW6PYJKlfxmg20bV4djUzFrXUzTubWrNrnxUin8IzGd8vfRNMZvWHjcCWGtu/vvmemO3dr2lBvPZAa58YMOnBbEnngsbEAIAM0xdeBuvCmsBjBhQpgZCQCzjvT/P3bHB/1v0886NHyerS9tcMcecfQhbrxQvMCNv9IWvmfPrPAzPdes3eLG88Uwe7O+4BdKbO/wM0OzjX4GaCYTfgbXvuzPb2d106DwTABXkPwqgD0A3BSN+TyAy0kuRPnf3YMAzu+VyYnsInSKT2QHddOgMMjrN7ONAD7sxC+p/sxEdg06xSciIomkIyiRfkL9oGR3oyMoERFJJC1QIiKSSN2e4luxcqUbz+XC7L5s1q+bNmIvv/vpmnV+Ztn69WGmWDY72B3b3Oln8WWbw4y40057uzv2pp+97Mb/ePuDbvwfL/xYEGvf7NeSW7FihRs/7PhjgthxR7/LHftq/kU3ftfdj7nxz33+20FsztzF7ti9x/mdbD/04RPd+OJF4fNZsdqvk4iUHy8Wws9OKe2/jw11YfdiAMjEfGoLxXA/zc31/mARSTxdgxLpJ7o2LFTjPtnV6RSfiIgkkhYokRoieSzJo2o9D5Ek0gIlUlvHolxgVkS66PYaVKbOv8CccVqqFUsMgwByr8WUq8n6ZYDS6bDEUGwZJT83Ae1OAsbkffyEgJNO9RMCfn/DtW58yuQJQWzEXn6Zoj/88T43/r0fhfu+8de3uWNvn/2AG3/5xeVunOkwKaV5hJ+oUl+/hxsv5v3SQ81Ds0FsxaqwOSQAvPP46W78t1d9JYhdf8M17tjVrX6Zoky9nzzRvuWVIFYqxnxIehnJjwG4CIABWAjgNwC+CiAD4BWUSyINQrnc0VaSZwG40MweqsmERRJISRIiVUZyf5QXo6PMbCPJJpQXqiPMzEh+EsA/m9mXSF4JIGdm36vlnEWSSAuUSPUdD+CWqP4ezKyN5AwAN5MchfJR1As92ZH6QcnuTNegRPrGTwBcZmYzAHwa5eaGb8nMrjKzWWY2a0D90F6doEjSaIESqb57AZxGcjgARKf4hgJ4Kdr+8YqxWwAM6dvpifQPWqBEqszMlqDchuMBkk8B+AGAS1BuBT8fwMaK4X8A8PcknyT5tj6frEiCdXsNatzYsW68szPM8ursfM1/gLSfKZaKiacHhPFSTDWddEwzxHQm3Edz03B37GEH+c0GT3nPj9z45Injg1h7u//c33n84W587frw8kM6JiXx1Pe+w4031PtVBEaOCjMK6+r9MlRI+RmWbev9MlTtm8IyRe8+wc/Wyzb5p6MGIHxvpk/397Hg8WVuvNwfMNSRC8tkpVN+xl9vM7NrAHRNTwxSNc1sGYAD+mRSIv2MjqBERCSRtECJiEgiKc1cpJ9Qw0LZ3egISkREEkkLlIiIJFK3p/ieWdrqxvOFsBhfIV9wxxZjMvDq6vzvKRZLYTZbR3vOHZuOmf2ECaOCWKngZ8kVC36zvM9++lw3vm5dq7MPf51fsfw5N97W9nwQy8Q0+Ms4GYkA0DzMz8xLOU37Nq571d/3IH/ea172myQ2NoaZkDOn7eOOXdG62o1f/rNfBLHmZj/jL1/w33fExAudYbw+679+/VHXflCy89RTK9l0BCUiIomkBUpERBJJC5RIFZBsIbnYif+C5LQe3P9skpf1zuxE+ielmYv0IjP7pBcnOcDMatOsSqSf0BGUSPWkSd5AcinJW0nWk7yf5CwAIJkj+f2oPt+RJM8huYzkYwCOru3URZKn+466Gb+OWbEQZpyVYurilZzuuwDQ2elnzxWKYX24xkY/y2vcGL++Xr6zI4gVXwvryAFAXUxNwJXPB2drAACPzX3SmZ/fp6c+478mDXXh61pynjcQnwXZsXmzG882OIWxYzIYV6/1a+7lnJp2ANCQCTssPzlvkTv297f53YSbmvYKYiefepg7Fin/Pctmw67LAFBXF75Y+ZjPWS/ZD8C5ZjaH5C8BfKbL9sEAHo0aFY4CcCOAQwBsBnAfgCf6crIiSacjKJHqedHM5kS3rwdwTJftWwH8X3T7cAD3m9kGMysAuNnbIcnzSM4jOW9rp/9HiciuSguUSPXYW/ye397rTmpYKLszLVAi1TOO5JHR7TMA/LWbsY8CeAfJ4ST3AHBar89OpJ/RAiVSPc8C+CzJpQCGAbgibqCZvYxyE8NHAMwBsLQvJijSn3SbJFFf51/kr0uFiQX5XMzF6KasG24cNcKN5zaFF+gbh/gXxVNO8zsAWLY83MdI/+GQz3U9C1P2tX/3v5KScl6xXNi/EQDQEPPcV67ZEsSG1sU0diz5r2ux6F+PaGwISyDlO2JKA8WUDOqMecz6bJgMUp8d5o5NxzwfpMLmjsWcP4+O9WGyCwCsL/rvWSrNcB7eG9YLzKwVwBRn07EVY9705pjZrwD8qlcnJtKP6QhKREQSSQuUiIgkkipJiPQTalgouxsdQYmISCJpgRIRkUTq9hRfe84vNZOBU+ooZqlLp/0NHZtjMsicx9y4do07tlSMmb5THqit3QsjrqMAAAr/SURBVM96G9E02o1P33+CG1+4ZEkQO+Lg6e7Yux6a68YH1ofliJqa/Yy/5kY/ns/7mXZrVoWvVS7nNyxMp/06Spby37PG5rC0VGfeT2F8rRDTJDEffk919Ytr3bHrVofZjgBQrAuz9QBgUP3gIDZypFP6SUT6BR1BiYhIImmBEhGRRNICJSIiiaQFSiQhSOprHyIV9A9CpBeQ/BiAi1CuaL4QwG8AfBVABsArAM40s3UkLwGwL4AJAFYBOL0mExZJoG4XqM6SX08t7dTo6+j0G+6l2vxss9Ex2VVt7WGttkLO3/e4MX6jwFWr1wexl1tfjtnHWDc+eUqLG//T3WEjvgMO9F/GrZ1+piJK4fNZu2qjO3T9qphGkDE15l4vhB0iOwv+65eOaSZZ1xA2Jiw/aJj1t+CJBe7QtvXr3PioaWG5ujFjx7hjx0/2Myk7YjIEi8UwQ7AY8xx7E8n9UV6MjjKzjSSbUF6ojjAzI/lJAP8M4EvRXaYBOMbMgg8/yfMAnAcA48aN65P5iySFjqBEqu94ALeY2UYAMLM2kjMA3Bx10s0AeKFi/GxvcYruexWAqwBg1qxZfpVckV2UrkGJ9I2fALjMzGYA+DSAuopt/iGhyG5OC5RI9d0L4DSSwwEgOsU3FMBL0faP12piIv2JTvGJVJmZLSH5LQAPkNwK4AmUmxPeQnITygvY+BpOUaRf6HaBqsv4F+gbh4RN8Z5+8ml37MyDprnxzvawqSAAlJzmdRNjkiHWrvZL5JSccklD6/2Ej9F7+Q336hr88dnGoUEsruzQh//+BDe+8KlHg1hcc8hO58I/AOQK/sFvJhvOb9GTz7ljU07jSQDocBJVAGBF60tBLJ97xR1bjEkQyThNBacf5JeKuv+RsKwUAKScRBAAKBXD9yGuqWVvM7NrAFzTJXybM+6SPpmQSD+kU3wiIpJIWqBERCSRtECJiEgiaYESEZFEUhafSD+x6KXNaLn49tjtrWoHL7uYbheoCaP8DLdCZ/i9wmNmTXLHjhgeZvwBQD5fcOPTx08NYs3ZQe7YNY3+voGBQaS92OGOnDDBb1g4caJfAumkd709iJ147BHu2FXLn3XjrUsfD2KnvO9od2wpXefG//uKW9345o3t4eOt9csOTW6Z6Mbf+R5/LhNbGoPYXbcHiWkAgEzMsXljNnzP6mNKK7V3+NmEuQ6/kWaDs59sNpyziPQPOsUnIiKJpAVKZAeRvJ/krFrPQ2RXpQVKREQSSQuUyFsg2ULyGZI3kFxK8laS9V3GXEFyHsklJP+zIt5K8j9JLiC5iOSUKD6Y5C9JPkbyCZKn9vXzEkk6LVAiPbMfgJ+a2VQAHQA+02X7V8xsFoADALyD5AEV2zaa2UwAV6DcxBAAvgLgXjM7DMBxAC4lObhXn4FIP9NtFt8nzjnZja9fFzYEXL5shTs2hbD2GgCMGTnC3/facN/ZmCy+lilhxh8AdDoNDp9e5jfWW7N6uRsvIaYOYUNY762YX+OOvfaaa914riOsX7d8uZ81+PCjC934tBb/9Ss68x4/0s92fG5ZWFsPAEaO9P9uKRTC+olF+HUIDz9qfzf+yXPfF8TmzX3IHYui38RxzAj/+dTVhx/nYt6vFbgDXjSzOdHt6wF8vsv2D0XNBdMARqHchHDbm/fb6L/zAXwgun0SgFNIbluw6gCMA7C0cqeVDQsHZP2alCK7Kn0PSqRnujYL/NvvJMejfGR0qJltInk13tzvadsqvhX//98cAXzQzPzvImx7kIqGhQNHTVLDQtmt6BSfSM+MI3lkdPsMAH+t2JZFuengZpJ7AXhPD/Z3J4ALSRIASB5czcmK7Aq0QIn0zLMAPktyKYBhKF9PAgCY2VMo93x6BsCNAOa4e3izbwDYA8BCkkui30Wkgk7xifRM0czO6hI7dtsNMzvbu5OZtVTcnrftPmb2Gsqt30Ukho6gREQkkbo9gpp9x31uPJUKM8U2bvQ75Gbr/Qy81lV+N9xcLh/EmprCLrEAMMIvo4dSMazhli/49dsKnWHGHwA89tJi/zGHhx1ab1rsZ9oddqTfTTid8l52v0vs248+0I1Pnux3DF++fGUQmz5rhjv24Xl+x9rWlX4H3ubhYW3GT5z7AWckkK3PuPFcZ5hVN3q0X29w1sF7u/G6jJ+NXXIyCgv5kjt2e5hZKwC/7a+I9Bqd4hPpJ2bsPRTzVLFcdiM6xSciIomkBUpERBJJC5SIiCRSt9eg1qze7MbbN4fN/7wL6ADQum6DG89k/Ivo3prZkdvqjuxY8aIbz+XCC/EtzcPdsWNGtLjxJ2+f78Y3bgwTMI441E9CyDZm3XixGDZrXL2q1R3b3OSX9Vm1xn9d806uRVxCSqHglymaPGmcG29oCOcS9xwbMmHTSABYvTqcS6YuTDwBgKYm/z2Le0wvSWLkiJHuWBFJPh1BiYhIImmBEhGRRNICJSIiiaTvQYn0E/Pnz8+R7Lb6eR9oBuD3QelbSZiH5lC9OezjBbVAifQfz0ZNEWuG5LxazyEp89Acen8ONFOLGZH+YFf/n1F/m4fm0Ptz0DUoERFJJC1QIv3HVbWeAJIxByAZ89AcynptDjrFJyIiiaQjKBERSSQtUCIJQ/LdJJ8luZzkxc72gSRvjrY/SrKlBnP4IsmnSS4keQ9JN024N+dQMe6DJI1k1S/U92QOJD8UvRZLSN5Y7Tn0ZB4kx5G8j+QT0XtycpUf/5ck15N0G+Wx7MfR/BaSnFmVBzYz/ehHPwn5ATAAwPMAJgDIAHgKwLQuYz4D4Mro9kcA3FyDORwHoD66fUEt5hCNGwLgQQBzAcyqweswCcATAIZFv4+o0WfiKgAXRLenAWit8hzeDmAmgMUx208GcAcAAjgCwKPVeFwdQYkky2EAlpvZCjMrALgJwKldxpwK4Jro9q0ATiDJvpyDmd1nZtvaVM8FMKaKj9+jOUS+AeC7AMJW3H0zh08BuNzMNgGAma2v0TwMwLYqykMBrKnmBMzsQQBt3Qw5FcC1VjYXQCPJUTv7uFqgRJJlbwCVZfpXRzF3jJkVAWwG4Jd+7705VDoX5b+eq+kt5xCdRhprZrdX+bF7PAcAkwFMJjmH5FyS767RPC4BcBbJ1QD+BODCXphHd7b3M9MjqiQhIjuM5FkAZgF4Rx8/bgrADwCc3ZeP60ijfJrvWJSPIh8kOcPM2vt4HqcDuNrMvk/ySADXkZxuZqU+nkdV6QhKJFleAjC24vcxUcwdQzKN8imdsAla784BJE8E8BUAp5iZ31ys9+YwBMB0APeTbEX5usfsKidK9OR1WA1gtpm9YWYvAFiG8oJVTT2Zx7kAfgMAZvYIgDqUa+T1lR59ZraXFiiRZHkcwCSS40lmUE6CmN1lzGwAH49u/wOAey26Ut1XcyB5MICfobw49cZ1l27nYGabzazZzFrMrAXl62CnmNm8vppD5PcoHz2BZDPKp/xWVHEOPZ3HKgAnRPOYivIC5Xc17R2zAXwsyuY7AsBmM3t5Z3eqU3wiCWJmRZKfA3AnytlbvzSzJSS/DmCemc0G8L8on8JZjvKF64/UYA6XAmgAcEuUn7HKzE7p4zn0qh7O4U4AJ5F8GsBWAF82s2oezfZ0Hl8C8HOS/4RywsTZ1fyjheSvUV6Im6PrXP8BYI9ofleifN3rZADLAXQCOKcqj1vdP7xERESqQ6f4REQkkbRAiYhIImmBEhGRRNICJSIiiaQFSkREEkkLlIiIJJIWKBERSSQtUCIikkj/D9S5aqsjKg/CAAAAAElFTkSuQmCC\n",
            "text/plain": [
              "<Figure size 432x648 with 2 Axes>"
            ]
          },
          "metadata": {
            "tags": [],
            "needs_background": "light"
          }
        }
      ]
    }
  ]
}